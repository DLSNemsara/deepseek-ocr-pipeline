{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLSNemsara/deepseek-ocr-pipeline/blob/main/DeepSeek_OCR_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# DeepSeek-OCR Document Processing Pipeline\n",
        "\n",
        "**Purpose:** Evaluate DeepSeek-OCR performance on high-volume legal document processing\n",
        "\n",
        "**Test Documents:**\n",
        "- Court documents (various types)\n",
        "- Multi-format support (PDF, TIFF, JPG, PNG)\n",
        "- Complex layouts with multi-column text\n",
        "- Handwritten and typed content\n",
        "\n",
        "**Output:**\n",
        "- Processed OCR results in markdown format\n",
        "- Comprehensive performance metrics report\n",
        "- Success rate and latency analysis\n",
        "\n",
        "**Model:** deepseek-ai/DeepSeek-OCR (bfloat16 precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: Install Dependencies\n",
        "# ============================================================================\n",
        "print(\"üì¶ Installing dependencies...\\n\")\n",
        "\n",
        "!pip install -q transformers==4.46.3 tokenizers==0.20.3 einops addict easydict pillow\n",
        "!pip install -q pdf2image PyPDF2\n",
        "!apt-get install -q poppler-utils  # For PDF processing\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Verify GPU and Environment\n",
        "# ============================================================================\n",
        "import torch\n",
        "import platform\n",
        "\n",
        "print(\"üîç Environment Check:\\n\")\n",
        "print(f\"Python Version: {platform.python_version()}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\n‚úÖ GPU is ready!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è WARNING: No GPU detected!\")\n",
        "    print(\"Go to: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
        "    raise RuntimeError(\"GPU not available. Please enable GPU runtime.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_documents"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 3: Upload Test Documents\n",
        "# ============================================================================\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"üì§ Upload your court documents (PDF, TIFF, JPG, PNG)\\n\")\n",
        "print(\"Select multiple files at once:\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    raise ValueError(\"No files uploaded. Please upload at least one document.\")\n",
        "\n",
        "# Create upload directory\n",
        "upload_dir = \"/content/uploads\"\n",
        "os.makedirs(upload_dir, exist_ok=True)\n",
        "\n",
        "# Move uploaded files\n",
        "uploaded_files = []\n",
        "for filename in uploaded.keys():\n",
        "    src = f\"/content/{filename}\"\n",
        "    dst = f\"{upload_dir}/{filename}\"\n",
        "    if os.path.exists(src):\n",
        "        os.rename(src, dst)\n",
        "        uploaded_files.append(dst)\n",
        "\n",
        "print(f\"\\n‚úÖ Uploaded {len(uploaded_files)} document(s):\")\n",
        "for f in uploaded_files:\n",
        "    size_mb = os.path.getsize(f) / (1024 * 1024)\n",
        "    print(f\"  - {os.path.basename(f)} ({size_mb:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_model"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Model Loading and Initialization\n",
        "# ============================================================================\n",
        "\"\"\"\n",
        "DeepSeek-OCR Model Loading\n",
        "Loads the DeepSeek-OCR model with optimized settings for high-accuracy OCR.\n",
        "\"\"\"\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "print(\"üöÄ Loading DeepSeek-OCR model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "MODEL_PATH = \"deepseek-ai/DeepSeek-OCR\"\n",
        "\n",
        "# Load tokenizer\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "if tokenizer.pad_token is None and tokenizer.eos_token is not None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Create offload directory for memory optimization\n",
        "offload_dir = \"/content/offload_folder\"\n",
        "os.makedirs(offload_dir, exist_ok=True)\n",
        "\n",
        "# Load model with memory optimizations\n",
        "print(\"Loading model (this takes 2-3 minutes)...\")\n",
        "start_time = time.time()\n",
        "\n",
        "model = AutoModel.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    trust_remote_code=True,\n",
        "    use_safetensors=True,\n",
        "    attn_implementation=\"eager\",  # Uses eager attention (not flash)\n",
        "    torch_dtype=torch.bfloat16,   # Explicit bfloat16 precision\n",
        "    device_map=\"auto\",\n",
        "    offload_folder=offload_dir\n",
        ").eval()  # Set to evaluation mode\n",
        "\n",
        "load_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Model loaded successfully in {load_time:.1f} seconds\")\n",
        "try:\n",
        "    print(f\"üìä Memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "except:\n",
        "    print(\"üìä Memory stats unavailable (model distributed automatically)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "convert_pdfs"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Convert PDFs/Tiffs to Images\n",
        "# ============================================================================\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "print(\"üîÑ Converting PDFs to images...\\n\")\n",
        "\n",
        "uploaded_files = glob.glob(\"/content/uploads/*\")\n",
        "print(f\"üìÇ Found {len(uploaded_files)} files in the uploads folder.\\n\")\n",
        "\n",
        "processed_dir = \"/content/processed\"\n",
        "os.makedirs(processed_dir, exist_ok=True)\n",
        "\n",
        "documents_to_process = []\n",
        "\n",
        "for file_path in uploaded_files:\n",
        "    filename = os.path.basename(file_path)\n",
        "    file_ext = os.path.splitext(filename)[1].lower()\n",
        "\n",
        "    if file_ext == '.pdf':\n",
        "        print(f\"Converting PDF: {filename}\")\n",
        "        try:\n",
        "            images = convert_from_path(file_path, dpi=300)\n",
        "            for i, img in enumerate(images):\n",
        "                output_path = f\"{processed_dir}/{os.path.splitext(filename)[0]}_page{i+1}.png\"\n",
        "                img.save(output_path, 'PNG')\n",
        "                documents_to_process.append({\n",
        "                    'path': output_path,\n",
        "                    'original': filename,\n",
        "                    'page': i+1,\n",
        "                    'type': 'PDF'\n",
        "                })\n",
        "            print(f\"  ‚úì Converted {len(images)} page(s)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó Error: {e}\")\n",
        "\n",
        "    elif file_ext in ['.tiff', '.tif']:\n",
        "        print(f\"Converting TIFF: {filename}\")\n",
        "        try:\n",
        "            img = Image.open(file_path)\n",
        "            # Check if multi-page TIFF\n",
        "            n_frames = getattr(img, 'n_frames', 1)\n",
        "\n",
        "            if n_frames > 1:\n",
        "                # Multi-page TIFF - process each page\n",
        "                print(f\"  Multi-page TIFF detected: {n_frames} pages\")\n",
        "                for i in range(n_frames):\n",
        "                    img.seek(i)  # Go to page i\n",
        "                    output_path = f\"{processed_dir}/{os.path.splitext(filename)[0]}_page{i+1}.png\"\n",
        "                    img.convert('RGB').save(output_path, 'PNG')\n",
        "                    documents_to_process.append({\n",
        "                        'path': output_path,\n",
        "                        'original': filename,\n",
        "                        'page': i+1,\n",
        "                        'type': 'TIFF'\n",
        "                    })\n",
        "                print(f\"  ‚úì Converted {n_frames} page(s)\")\n",
        "            else:\n",
        "                # Single-page TIFF\n",
        "                output_path = f\"{processed_dir}/{os.path.splitext(filename)[0]}.png\"\n",
        "                img.convert('RGB').save(output_path, 'PNG')\n",
        "                documents_to_process.append({\n",
        "                    'path': output_path,\n",
        "                    'original': filename,\n",
        "                    'page': 1,\n",
        "                    'type': 'TIFF'\n",
        "                })\n",
        "                print(f\"  ‚úì Converted (single page)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó Error: {e}\")\n",
        "\n",
        "    elif file_ext in ['.jpg', '.jpeg', '.png']:\n",
        "        print(f\"Using image: {filename}\")\n",
        "        documents_to_process.append({\n",
        "            'path': file_path,\n",
        "            'original': filename,\n",
        "            'page': 1,\n",
        "            'type': file_ext.upper().replace('.', '')\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping unsupported format: {filename}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Ready to process {len(documents_to_process)} document(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Document Processing Loop\n",
        "# ============================================================================\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import json\n",
        "import torch\n",
        "\n",
        "print(\"üìÑ Processing documents with DeepSeek-OCR...\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Configuration:\")\n",
        "print(\"  - Prompt: Native DeepSeek-OCR format\")\n",
        "print(\"  - Mode: Zero-shot OCR\")\n",
        "print(\"  - Setting: test_compress=False (maximum accuracy)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results_dir = \"/content/results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Native DeepSeek-OCR prompt\n",
        "full_prompt = \"<image>\\nConvert the text in this image to markdown.\"\n",
        "\n",
        "processing_results = []\n",
        "\n",
        "if 'documents_to_process' not in locals():\n",
        "    print(\"\\n‚ö†Ô∏è Error: 'documents_to_process' list is missing.\")\n",
        "    print(\"Please run Cell 5 (PDF conversion) first to prepare documents.\\n\")\n",
        "else:\n",
        "    for idx, doc in enumerate(documents_to_process, 1):\n",
        "        doc_name = f\"{doc['original']} (Page {doc['page']})\"\n",
        "        print(f\"\\n[{idx}/{len(documents_to_process)}] Processing: {doc_name}\")\n",
        "\n",
        "        doc_output_dir = f\"{results_dir}/doc_{idx:03d}\"\n",
        "        os.makedirs(doc_output_dir, exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                ocr_result = model.infer(\n",
        "                    tokenizer,\n",
        "                    prompt=full_prompt,\n",
        "                    image_file=doc['path'],\n",
        "                    output_path=doc_output_dir,\n",
        "                    base_size=1024,\n",
        "                    image_size=640,\n",
        "                    crop_mode=True,\n",
        "                    save_results=True,\n",
        "                    test_compress=False  # Maximum accuracy mode\n",
        "                )\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            # Read OCR output\n",
        "            output_files = os.listdir(doc_output_dir)\n",
        "            mmd_file = [f for f in output_files if f.endswith('.mmd')]\n",
        "\n",
        "            ocr_text = \"\"\n",
        "            if mmd_file:\n",
        "                with open(f\"{doc_output_dir}/{mmd_file[0]}\", 'r', encoding='utf-8') as f:\n",
        "                    ocr_text = f.read()\n",
        "\n",
        "            # Store results\n",
        "            result = {\n",
        "                'document': doc_name,\n",
        "                'original_file': doc['original'],\n",
        "                'page': doc['page'],\n",
        "                'file_type': doc['type'],\n",
        "                'processing_time': round(processing_time, 2),\n",
        "                'output_dir': doc_output_dir,\n",
        "                'ocr_text_length': len(ocr_text),\n",
        "                'status': 'success'\n",
        "            }\n",
        "            processing_results.append(result)\n",
        "\n",
        "            print(f\"  ‚úÖ Completed in {processing_time:.2f}s\")\n",
        "            print(f\"  ‚úÖ Extracted {len(ocr_text):,} characters\")\n",
        "\n",
        "            # Preview\n",
        "            if len(ocr_text) > 0:\n",
        "                preview_len = min(100, len(ocr_text))\n",
        "                clean_preview = ocr_text[:preview_len].replace('\\n', ' ')\n",
        "                print(f\"  Preview: {clean_preview}...\")\n",
        "            else:\n",
        "                print(\"  ‚ö†Ô∏è Warning: Output is empty\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error: {str(e)}\")\n",
        "            processing_results.append({\n",
        "                'document': doc_name,\n",
        "                'original_file': doc['original'],\n",
        "                'page': doc['page'],\n",
        "                'file_type': doc['type'],\n",
        "                'status': 'failed',\n",
        "                'error': str(e)\n",
        "            })\n",
        "\n",
        "    # Save results metadata\n",
        "    with open(f\"{results_dir}/processing_metadata.json\", 'w') as f:\n",
        "        json.dump(processing_results, f, indent=2)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ Processing complete!\")\n",
        "    print(f\"  Successful: {sum(1 for r in processing_results if r['status'] == 'success')}\")\n",
        "    print(f\"  Failed: {sum(1 for r in processing_results if r['status'] == 'failed')}\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "LnlHD6ZQBBs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copies results to Google Drive\n",
        "# The source path is your generated results folder\n",
        "SOURCE_PATH = \"/content/results\"\n",
        "\n",
        "# The destination path is inside your Google Drive\n",
        "DESTINATION_PATH = \"/content/drive/MyDrive/OCR_Results\"\n",
        "\n",
        "!cp -r \"$SOURCE_PATH\" \"$DESTINATION_PATH\"\n"
      ],
      "metadata": {
        "id": "LbwRnBGCDQ4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_report"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 7: Generate Performance Report\n",
        "# ============================================================================\n",
        "\"\"\"\n",
        "Generates a technical performance report for OCR processing.\n",
        "Focuses on metrics: latency, throughput, success rate, and file type distribution.\n",
        "\"\"\"\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üìä Generating performance report...\\n\")\n",
        "\n",
        "# Calculate statistics\n",
        "successful_results = [r for r in processing_results if r['status'] == 'success']\n",
        "failed_results = [r for r in processing_results if r['status'] == 'failed']\n",
        "\n",
        "if successful_results:\n",
        "    avg_time = sum(r['processing_time'] for r in successful_results) / len(successful_results)\n",
        "    total_time = sum(r['processing_time'] for r in successful_results)\n",
        "    total_chars = sum(r['ocr_text_length'] for r in successful_results)\n",
        "    min_time = min(r['processing_time'] for r in successful_results)\n",
        "    max_time = max(r['processing_time'] for r in successful_results)\n",
        "else:\n",
        "    avg_time = total_time = total_chars = min_time = max_time = 0\n",
        "\n",
        "# File type breakdown\n",
        "type_counts = {}\n",
        "type_success = {}\n",
        "for r in processing_results:\n",
        "    ftype = r['file_type']\n",
        "    type_counts[ftype] = type_counts.get(ftype, 0) + 1\n",
        "    if r['status'] == 'success':\n",
        "        type_success[ftype] = type_success.get(ftype, 0) + 1\n",
        "\n",
        "# Filename masking function for privacy\n",
        "def mask_filename(filename, index):\n",
        "    \"\"\"Masks filename while preserving extension.\"\"\"\n",
        "    ext = Path(filename).suffix\n",
        "    return f\"Document_{index:02d}{ext}\"\n",
        "\n",
        "# Generate report\n",
        "report = f\"\"\"# DeepSeek-OCR Performance Report\n",
        "## High-Volume Legal Document OCR Analysis\n",
        "\n",
        "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "**Model:** deepseek-ai/DeepSeek-OCR\n",
        "**Precision:** bfloat16 (Full precision, no quantization)\n",
        "**Compression:** Disabled (test_compress=False for maximum accuracy)\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "This report evaluates DeepSeek-OCR performance on a diverse set of legal documents including court orders, citations, and judgment records.\n",
        "\n",
        "### Processing Results\n",
        "\n",
        "- **Total Documents:** {len(processing_results)}\n",
        "- **Successful:** {len(successful_results)}\n",
        "- **Failed:** {len(failed_results)}\n",
        "- **Success Rate:** {(len(successful_results)/len(processing_results)*100):.1f}%\n",
        "\n",
        "### Performance Metrics\n",
        "\n",
        "**Latency:**\n",
        "- **Average:** {avg_time:.2f} seconds/document\n",
        "- **Minimum:** {min_time:.2f} seconds\n",
        "- **Maximum:** {max_time:.2f} seconds\n",
        "\n",
        "**Throughput:**\n",
        "- **Total Processing Time:** {total_time:.2f} seconds\n",
        "- **Estimated Throughput:** {len(successful_results)/total_time*3600:.0f} documents/hour\n",
        "\n",
        "**Text Extraction:**\n",
        "- **Total Characters Extracted:** {total_chars:,}\n",
        "- **Average per Document:** {total_chars/len(successful_results) if successful_results else 0:,.0f} characters\n",
        "\n",
        "---\n",
        "\n",
        "## File Type Analysis\n",
        "\n",
        "| File Type | Total | Successful | Success Rate |\n",
        "|-----------|-------|------------|--------------|\n",
        "\"\"\"\n",
        "\n",
        "for ftype in sorted(type_counts.keys()):\n",
        "    total = type_counts[ftype]\n",
        "    success = type_success.get(ftype, 0)\n",
        "    rate = (success / total * 100) if total > 0 else 0\n",
        "    report += f\"| {ftype} | {total} | {success} | {rate:.1f}% |\\n\"\n",
        "\n",
        "report += f\"\"\"\\n---\n",
        "\n",
        "## Document Processing Details\n",
        "\n",
        "| Document ID | Type | Time (s) | Characters | Status |\n",
        "|-------------|------|----------|------------|--------|\n",
        "\"\"\"\n",
        "\n",
        "# Add each document with masked filename\n",
        "for idx, r in enumerate(processing_results, 1):\n",
        "    masked_name = mask_filename(r['document'], idx)\n",
        "    time_str = f\"{r.get('processing_time', 0):.2f}\" if r['status'] == 'success' else \"N/A\"\n",
        "    chars_str = f\"{r.get('ocr_text_length', 0):,}\" if r['status'] == 'success' else \"N/A\"\n",
        "    status_icon = \"‚úÖ\" if r['status'] == 'success' else \"‚ùå\"\n",
        "    report += f\"| {masked_name} | {r['file_type']} | {time_str} | {chars_str} | {status_icon} |\\n\"\n",
        "\n",
        "report += f\"\"\"\\n---\n",
        "\n",
        "## Technical Observations\n",
        "\n",
        "### Model Strengths\n",
        "- Preserves complex document layouts in markdown format\n",
        "- Handles multi-column text and structured data effectively\n",
        "- Supports multiple file formats (PDF, TIFF, JPG, PNG)\n",
        "- Maintains high accuracy with test_compress=False setting\n",
        "\n",
        "### Performance Characteristics\n",
        "- Processing time varies with document complexity and file size\n",
        "- bfloat16 precision provides optimal accuracy-speed balance\n",
        "- Single GPU inference suitable for moderate-volume workloads\n",
        "\n",
        "### Areas for Consideration\n",
        "- Handwritten text may require post-processing verification\n",
        "- Checkbox/form field states may need additional parsing logic\n",
        "- Large TIFF files benefit from preprocessing optimization\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration Details\n",
        "\n",
        "**Model Settings:**\n",
        "```python\n",
        "torch_dtype: torch.bfloat16\n",
        "test_compress: False  # Maximum accuracy mode\n",
        "max_new_tokens: 4096\n",
        "do_sample: False      # Deterministic output\n",
        "```\n",
        "\n",
        "**Processing Pipeline:**\n",
        "- Native DeepSeek-OCR prompt (no custom modifications)\n",
        "- No image compression (prioritizes accuracy over speed)\n",
        "- Deterministic generation (consistent outputs)\n",
        "- UTF-8 encoding for full Unicode support\n",
        "\n",
        "---\n",
        "\n",
        "**Report Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "\n",
        "# Save report\n",
        "report_path = os.path.join(results_dir, \"DeepSeek_OCR_Performance_Report.md\")\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"‚úÖ Report generated successfully!\")\n",
        "print(f\"üìÑ Report saved to: {report_path}\")\n",
        "print(f\"\\nüìä Quick Stats:\")\n",
        "print(f\"   Success Rate: {(len(successful_results)/len(processing_results)*100):.1f}%\")\n",
        "print(f\"   Avg Latency: {avg_time:.2f}s/document\")\n",
        "print(f\"   Total Characters: {total_chars:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_report"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 8: Display Report\n",
        "# ============================================================================\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "print(\"üìã Displaying Report:\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "with open(report_path, 'r', encoding='utf-8') as f:\n",
        "    report_content = f.read()\n",
        "\n",
        "display(Markdown(report_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "view_sample_outputs"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 9: View Sample OCR Outputs\n",
        "# ============================================================================\n",
        "from IPython.display import Image as IPyImage, display, Markdown\n",
        "import glob\n",
        "\n",
        "print(\"üëÄ Sample OCR Outputs\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, result in enumerate(successful_results[:3], 1):  # Show first 3\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Document {idx}: {result['document']}\")\n",
        "    print(f\"Processing Time: {result['processing_time']:.2f}s\")\n",
        "    print(f\"=\"*70)\n",
        "\n",
        "    # Show bounding box overlay if available\n",
        "    overlay = f\"{result['output_dir']}/result_with_boxes.jpg\"\n",
        "    if os.path.exists(overlay):\n",
        "        print(\"\\nüîç Detected Text Regions:\")\n",
        "        display(IPyImage(filename=overlay, width=800))\n",
        "\n",
        "    # Show OCR text (first 500 chars)\n",
        "    mmd_files = glob.glob(f\"{result['output_dir']}/*.mmd\")\n",
        "    if mmd_files:\n",
        "        with open(mmd_files[0], 'r', encoding='utf-8') as f:\n",
        "            ocr_text = f.read()\n",
        "\n",
        "        print(\"\\nüìù OCR Output (preview):\")\n",
        "        print(\"-\"*70)\n",
        "        display(Markdown(ocr_text[:500] + \"\\n\\n[...truncated...]\"))\n",
        "\n",
        "print(f\"\\n\\nüí° Full OCR outputs are saved in individual folders.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 10: Package and Download Results\n",
        "# ============================================================================\n",
        "import shutil\n",
        "from google.colab import files as colab_files\n",
        "\n",
        "print(\"üì¶ Packaging results for download...\\n\")\n",
        "\n",
        "# Create zip file\n",
        "archive_name = f\"DUCS_DeepSeek_OCR_Results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "archive_path = f\"/content/{archive_name}\"\n",
        "\n",
        "print(f\"Creating archive: {archive_name}.zip\")\n",
        "shutil.make_archive(archive_path, 'zip', results_dir)\n",
        "\n",
        "print(f\"\\nArchive size: {os.path.getsize(f'{archive_path}.zip') / (1024*1024):.2f} MB\")\n",
        "print(\"\\nüì• Downloading...\")\n",
        "\n",
        "# Download the report separately (small file)\n",
        "print(\"\\n1. Downloading report (Markdown)...\")\n",
        "colab_files.download(report_path)\n",
        "\n",
        "# Download the full archive\n",
        "print(\"\\n2. Downloading full results archive (all OCR outputs)...\")\n",
        "colab_files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print(\"\\n‚úÖ Download complete!\")\n",
        "print(\"\\nContents of the archive:\")\n",
        "print(\"  - Processing metadata (JSON)\")\n",
        "print(\"  - Performance report (Markdown)\")\n",
        "print(\"  - Individual OCR outputs for each document\")\n",
        "print(\"  - Bounding box overlays (images)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}